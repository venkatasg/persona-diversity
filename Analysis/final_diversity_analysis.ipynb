{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b2ac6a1-081d-45f3-a091-56a4aaa8829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ipdb\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from diversity import compression_ratio, ngram_diversity_score, extract_patterns, get_pos, pos_patterns, token_patterns, self_repetition_score\n",
    "import json\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from transformers import AutoTokenizer\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import mplcursors\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid', context='notebook', rc={'figure.figsize':(14,10), 'font.family': 'Times'}, font_scale=3)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('chained_assignment',None)\n",
    "\n",
    "# Set random seeds for reproducibility on a specific machine\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "np.random.RandomState(1)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a24c7ef-0cf7-4d8b-9ac4-09d9ad0dbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cr_nds_sr(responses):\n",
    "    cr = compression_ratio(responses, 'gzip')\n",
    "    nds = ngram_diversity_score(responses, 4)\n",
    "    #CR-POS\n",
    "    joined_pos, tuples = get_pos(responses)\n",
    "    # ngrams_pos = token_patterns(joined_pos, 5, 10)\n",
    "    cr_pos = compression_ratio(joined_pos, 'gzip')\n",
    "    srep = self_repetition_score(responses, verbose=False)\n",
    "    return cr, cr_pos, nds, srep\n",
    "\n",
    "def calc_diversity(df, num_shuffles=10):\n",
    "    '''\n",
    "    Randomly assigns personas with prompts, calculates metrics over responses for these\n",
    "    pairings, then calculates mean and S.D over 10 different random pairings\n",
    "    '''\n",
    "    random.seed(1)\n",
    "    crs = []\n",
    "    ndss = []\n",
    "    crs_pos = []\n",
    "    sreps = []\n",
    "    new_df = df.set_index(['persona_id', 'prompt_id'])\n",
    "    for _ in tqdm(range(num_shuffles)):\n",
    "        # Get random personas paired with every prompt\n",
    "        persona_ids_shuffled = [i for i in range(100)]\n",
    "        random.shuffle(persona_ids_shuffled)\n",
    "        prompt_ids = [i for i in range(100)]\n",
    "        pairs = list(zip(persona_ids_shuffled, prompt_ids))\n",
    "        responses = new_df.loc[pairs, 'response'].values.tolist()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        cr, cr_pos, nds, srep = calc_cr_nds_sr(responses)\n",
    "    \n",
    "        crs.append(cr)\n",
    "        ndss.append(nds)\n",
    "        crs_pos.append(cr_pos)\n",
    "        sreps.append(srep)\n",
    "    \n",
    "    print(f\"CR: {np.round(np.mean(crs),2)} ± {np.round(np.std(crs),2)}\\nCR-POS: {np.round(np.mean(crs_pos),2)} ± {np.round(np.std(crs_pos),2)}\\nNDS: {np.round(np.mean(ndss),2)} ± {np.round(np.std(ndss),2)}\\nSelf-rep:{np.round(np.mean(sreps),2)} ± {np.round(np.std(sreps),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f0b56-9c5f-4f23-a51d-ae53a9d9458e",
   "metadata": {},
   "source": [
    "## Dolly human responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87eebce1-cd67-49bc-96b9-f4d10a5105e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sample_personas.txt', 'r') as f:\n",
    "    personas = [x.strip() for x in f.readlines()]\n",
    "dolly = load_dataset(\"databricks/databricks-dolly-15k\")[\"train\"].filter(lambda row: row['category']=='creative_writing').to_pandas()\n",
    "sample = pd.read_csv('../data/dolly_creative_prompts_sample.tsv', sep='\\t')\n",
    "sample['response'] = sample['index'].apply(lambda x: dolly.loc[x, 'response'])\n",
    "sample['prompt_id'] = [i for i in range(len(sample))]\n",
    "prompts = sample['instruction'].values.tolist()\n",
    "human_responses = sample['response'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c6ee1b-bc92-4414-b67b-f695ebfd383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating self-repetition score: 100%|███████████████████████████████████████████████████████| 100/100 [00:00<00:00, 78062.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.51\n",
      "NDS: 3.03\n",
      "CR-POS: 4.93\n",
      "Self-rep: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cr = compression_ratio(human_responses, 'gzip')\n",
    "nds = ngram_diversity_score(human_responses, 4)\n",
    "joined_pos, tuples = get_pos(human_responses)\n",
    "# ngrams_pos = token_patterns(joined_pos, 5, 10)\n",
    "cr_pos = compression_ratio(joined_pos, 'gzip')\n",
    "# rouge = homogenization_score(human_responses, 'rougel', verbose=False)\n",
    "# bleu = homogenization_score(human_responses, 'bleu', verbose=False)\n",
    "srep = self_repetition_score(human_responses)\n",
    "# print(f\"CR: {np.round(cr,2)}\\nNDS: {np.round(nds,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nHS-RougeL: {np.round(rouge,2)}\\nself-bleu: {np.round(bleu,2)}\\nSelf-rep: {np.round(srep, 2)}\")\n",
    "print(f\"CR: {np.round(cr,2)}\\nNDS: {np.round(nds,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c69f0-e14a-4cd0-a584-75ed53878414",
   "metadata": {},
   "source": [
    "## Llama-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f178277a-9cdc-4987-ad65-ee18cd4176d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.77\n",
      "CR-POS: 5.73\n",
      "NDS: 2.87\n",
      "Self-rep: 1.89\n"
     ]
    }
   ],
   "source": [
    "# No persona, no cutoff\n",
    "np70_df = pd.read_csv('../output/llama-temp1/llama70b-np/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "np70_df['response'] = np70_df.response.apply(lambda x: x.strip())\n",
    "np70_df = np70_df.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(np70_df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8434efba-be0d-4a80-b553-3c310b6f4015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.57\n",
      "CR-POS: 5.16\n",
      "NDS: 3.08\n",
      "Self-rep: 0.52\n"
     ]
    }
   ],
   "source": [
    "# No persona with cutoff\n",
    "npc70_df = pd.read_csv('../output/llama-temp1/llama70b-cutoff-np/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "npc70_df['response'] = npc70_df.response.apply(lambda x: x.strip())\n",
    "npc70_df = npc70_df.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(npc70_df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d70942c7-e812-4b7e-8aa5-32c0cd26fbd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[(53, 0), (37, 1), (65, 2), (51, 3), (4, 4), (38, 6), (9, 7), (10, 8), (81, 9), (44, 10), (36, 11), (84, 12), (50, 13), (96, 14), (90, 15), (66, 16), (80, 18), (52, 21), (91, 22), (99, 23), (64, 24), (5, 25), (58, 26), (76, 27), (39, 28), (79, 29), (94, 31), (73, 33), (47, 35), (45, 37), (87, 39), (42, 40), (68, 41), (95, 42), (7, 44), (67, 45), (46, 46), (82, 47), (11, 48), (6, 49), (41, 50), (86, 51), (88, 52), (70, 53), (78, 55), (71, 56), (59, 57), (43, 58), (61, 59), (14, 61), (93, 63), (56, 64), (98, 66), (54, 67), (89, 69), (1, 70), (69, 71), (74, 72), (2, 73), (85, 74), (40, 75), (13, 76), (75, 77), (92, 80), (0, 81), (77, 82), (55, 83), (49, 84), (3, 85), (62, 86), (12, 87), (48, 89), (83, 90), (60, 91), (57, 92), (63, 93), (8, 96), (97, 97), (72, 98)] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m persona70_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m persona70_df\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m      3\u001b[0m persona70_df \u001b[38;5;241m=\u001b[39m persona70_df\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpersona_id\u001b[39m\u001b[38;5;124m'\u001b[39m], keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m calc_diversity(persona70_df, num_shuffles\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m, in \u001b[0;36mcalc_diversity\u001b[0;34m(df, num_shuffles)\u001b[0m\n\u001b[1;32m     26\u001b[0m prompt_ids \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)]\n\u001b[1;32m     27\u001b[0m pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(persona_ids_shuffled, prompt_ids))\n\u001b[0;32m---> 28\u001b[0m responses \u001b[38;5;241m=\u001b[39m new_df\u001b[38;5;241m.\u001b[39mloc[pairs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[1;32m     31\u001b[0m cr, cr_pos, nds, srep \u001b[38;5;241m=\u001b[39m calc_cr_nds_sr(responses)\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexing.py:1185\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexing.py:1369\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1368\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1372\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexing.py:1042\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# we may have a nested tuples indexer here\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_nested_tuple_indexer(tup):\n\u001b[0;32m-> 1042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_nested_tuple(tup)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;66;03m# we maybe be using a tuple to represent multiple dimensions here\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m ax0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexing.py:1154\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_nested_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     axis \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39m_getitem_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1155\u001b[0m axis \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;66;03m# if we have a scalar, we are done\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexing.py:1421\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexing.py:1361\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1361\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1363\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1364\u001b[0m )\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexing.py:1559\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1556\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1557\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1559\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2766\u001b[0m, in \u001b[0;36mMultiIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   2763\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(key, indexer, axis_name)\n\u001b[1;32m   2764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[indexer], indexer\n\u001b[0;32m-> 2766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2786\u001b[0m, in \u001b[0;36mMultiIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   2784\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_raise_if_missing(key, indexer, axis_name)\n",
      "File \u001b[0;32m~/micromamba/envs/diversity/lib/python3.11/site-packages/pandas/core/indexes/base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[(53, 0), (37, 1), (65, 2), (51, 3), (4, 4), (38, 6), (9, 7), (10, 8), (81, 9), (44, 10), (36, 11), (84, 12), (50, 13), (96, 14), (90, 15), (66, 16), (80, 18), (52, 21), (91, 22), (99, 23), (64, 24), (5, 25), (58, 26), (76, 27), (39, 28), (79, 29), (94, 31), (73, 33), (47, 35), (45, 37), (87, 39), (42, 40), (68, 41), (95, 42), (7, 44), (67, 45), (46, 46), (82, 47), (11, 48), (6, 49), (41, 50), (86, 51), (88, 52), (70, 53), (78, 55), (71, 56), (59, 57), (43, 58), (61, 59), (14, 61), (93, 63), (56, 64), (98, 66), (54, 67), (89, 69), (1, 70), (69, 71), (74, 72), (2, 73), (85, 74), (40, 75), (13, 76), (75, 77), (92, 80), (0, 81), (77, 82), (55, 83), (49, 84), (3, 85), (62, 86), (12, 87), (48, 89), (83, 90), (60, 91), (57, 92), (63, 93), (8, 96), (97, 97), (72, 98)] not in index'"
     ]
    }
   ],
   "source": [
    "persona70_df = pd.read_csv('../output/llama-temp1/llama70b-persona/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "persona70_df['response'] = persona70_df.response.apply(lambda x: x.strip())\n",
    "persona70_df = persona70_df.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "calc_diversity(persona70_df, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a0a8e5a-f64b-4c67-8a97-1ed42940ad70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1984, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona70_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d9439fd-6c86-4e8d-98fe-1ee21ed7652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:38<00:00,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.51 ± 0.02\n",
      "CR-POS: 5.04 ± 0.03\n",
      "NDS: 3.08 ± 0.02\n",
      "Self-rep:0.68 ± 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Persona plus cutoff\n",
    "personac70_df = pd.read_csv('../output/llama-temp1/llama70b-cutoff-persona/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "personac70_df['response'] = personac70_df.response.apply(lambda x: x.strip())\n",
    "calc_diversity(personac70_df, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0b8eaa-a50e-4348-b139-0f84912ad806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:52<00:00,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.51 ± 0.02\n",
      "CR-POS: 5.06 ± 0.04\n",
      "NDS: 3.09 ± 0.02\n",
      "Self-rep:0.61 ± 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse personas plus cutoff\n",
    "persona70_df_coarse = pd.read_csv('../output/llama-temp1/llama70b-coarse-cutoff-persona/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "persona70_df_coarse['response'] = persona70_df_coarse.response.apply(lambda x: x.strip())\n",
    "persona70_df_coarse = persona70_df_coarse.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "calc_diversity(persona70_df_coarse, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002f398-ec29-407c-bb0d-362c57f54f4b",
   "metadata": {},
   "source": [
    "## Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23c10561-66b5-4d44-94ff-b6ab7822c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No persona, no cutoff\n",
    "deep_npnc = pd.read_csv('../output/deepseek/deepseek-np/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_npnc['response'] = deep_npnc.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(deep_npnc['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "417d8b38-6756-449d-9917-7d46941bc6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.29\n",
      "CR-POS: 4.95\n",
      "NDS: 3.32\n",
      "Self-rep: 0.11\n"
     ]
    }
   ],
   "source": [
    "# No persona, cutoff\n",
    "deep_npc = pd.read_csv('../output/deepseek-np-cutoff/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_npc['response'] = deep_npc.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(deep_npc['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e648e96e-7c4c-41f3-bfeb-199ae8b5824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persona\n",
    "deep_p = pd.read_csv('../output/deepseek/deepseek-persona/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_p['response'] = deep_p.response.apply(lambda x: x.strip())\n",
    "deep_p = deep_p.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "# calc_diversity(deep_p, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fe93f98-e227-4b34-954f-4a78f6a2ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persona cutoff\n",
    "deep_pc = pd.read_csv('../output/deepseek-cutoff-persona/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_pc['response'] = deep_pc.response.apply(lambda x: x.strip())\n",
    "deep_pc = deep_pc.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "# calc_diversity(deep_pc, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "357b87a6-f7e7-40cb-9b23-c8492890e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:37<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.22 ± 0.02\n",
      "CR-POS: 4.77 ± 0.04\n",
      "NDS: 3.37 ± 0.02\n",
      "Self-rep:0.09 ± 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse persona cutoff\n",
    "deep_pc_coarse = pd.read_csv('../output/coarse/deepseek-cutoff-persona/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_pc_coarse['response'] = deep_pc_coarse.response.apply(lambda x: x.strip())\n",
    "deep_pc_coarse = deep_pc_coarse.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(deep_pc_coarse,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f414294-7e24-499a-bccb-1fa96dfd05bd",
   "metadata": {},
   "source": [
    "## Llama-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1369fcea-8317-4bbd-ad48-b29e1e08a5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.78\n",
      "CR-POS: 5.91\n",
      "NDS: 2.84\n",
      "Self-rep: 1.88\n"
     ]
    }
   ],
   "source": [
    "# No persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-np/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c04e539-7f50-4472-987e-54337acad399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.57\n",
      "CR-POS: 5.36\n",
      "NDS: 3.07\n",
      "Self-rep: 0.6\n"
     ]
    }
   ],
   "source": [
    "# No persona, plus cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-cutoff-np/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8bd9161-60f8-497a-8175-7ae88694047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:51<00:00,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.69 ± 0.02\n",
      "CR-POS: 5.46 ± 0.04\n",
      "NDS: 2.83 ± 0.02\n",
      "Self-rep:2.34 ± 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14395b29-4b8d-422d-b72f-7a6b048c4ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [10:30<00:00,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.52 ± 0.02\n",
      "CR-POS: 5.15 ± 0.04\n",
      "NDS: 3.04 ± 0.03\n",
      "Self-rep:0.94 ± 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine persona, cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-cutoff-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e77b62d-b820-4c12-9f0f-546f70ab081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:27<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.7 ± 0.02\n",
      "CR-POS: 5.52 ± 0.04\n",
      "NDS: 2.84 ± 0.02\n",
      "Self-rep:2.25 ± 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-coarse-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0aa4d27-ca35-4f96-b6bc-8910f9addcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:39<00:00,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.52 ± 0.02\n",
      "CR-POS: 5.17 ± 0.04\n",
      "NDS: 3.06 ± 0.02\n",
      "Self-rep:0.84 ± 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse persona with cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-coarse-cutoff-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df08e3-ad61-4f35-bbe9-c0540cb041dd",
   "metadata": {},
   "source": [
    "## Llama-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005ec794-4df6-4b2a-8a25-c1812a8f8def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.83\n",
      "CR-POS: 5.87\n",
      "NDS: 2.8\n",
      "Self-rep: 2.13\n"
     ]
    }
   ],
   "source": [
    "# No persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama1b-np/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f70eb176-e8e5-474d-b66b-ac3f483d2b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.58\n",
      "CR-POS: 5.35\n",
      "NDS: 3.03\n",
      "Self-rep: 0.69\n"
     ]
    }
   ],
   "source": [
    "# No persona, cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama1b-cutoff-np/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fbbc726-cbd2-42db-b9ad-69fcf13e6ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:42<00:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.72 ± 0.02\n",
      "CR-POS: 5.47 ± 0.05\n",
      "NDS: 2.8 ± 0.03\n",
      "Self-rep:2.34 ± 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama1b-persona/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adaa14c-450b-457e-b492-54ff58b73819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:54<00:00,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.56 ± 0.02\n",
      "CR-POS: 5.22 ± 0.04\n",
      "NDS: 2.99 ± 0.02\n",
      "Self-rep:0.99 ± 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama1b-cutoff-persona/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b9dab-18d3-4f30-a2f9-40a61ab15fe7",
   "metadata": {},
   "source": [
    "## Response length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc282d6-6773-4a1d-a10c-50f6cb5979df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29616, 44388]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-V3-0324')\n",
    "tokenizer('world hello', add_special_tokens=False)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e31c9d2a-50d4-43af-a61d-080838bccee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = {'len': [], 'source':[]}\n",
    "\n",
    "# Load all the human responses first.\n",
    "len_df['len'] += sample['response'].apply(lambda x: len(tokenizer(x, add_special_tokens=False)['input_ids'])).values.tolist()\n",
    "len_df['source'] += ['Dolly' for _ in range(len(sample))]\n",
    "\n",
    "for (df, source_name) in [(deep_npnc,'Deepseek-NP'), (deep_p, 'Deepseek-FP')]:\n",
    "    if df.shape[0]>100:\n",
    "        df['len'] = df.response.apply(lambda x: len(tokenizer(x, add_special_tokens=False)['input_ids']))\n",
    "        len_df['len'] += df.loc[:, ['prompt_id', 'len']].groupby('prompt_id').mean().len.values.tolist()\n",
    "    else:\n",
    "        len_df['len'] += df['response'].apply(lambda x: len(tokenizer(x, add_special_tokens=False)['input_ids'])).values.tolist()\n",
    "    len_df['source'] += [source_name for _ in range(100)]\n",
    "    \n",
    "len_df=pd.DataFrame(len_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b362f327-229d-48f7-bf4a-d7d1e82948ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.kdeplot(len_df, x='len', hue='source', common_norm=False, fill=True, clip=[0,1500])\n",
    "g.set_xlabel('Completion length (tokens)')\n",
    "g.set_ylabel('')\n",
    "g.spines[\"top\"].set_visible(False)\n",
    "g.spines[\"right\"].set_visible(False)\n",
    "g.spines[\"left\"].set_visible(False)\n",
    "g.set(yticklabels=[])\n",
    "g.grid(axis='x')\n",
    "# plt.legend([], [], frameon=False)\n",
    "# plt.show()\n",
    "plt.savefig('length.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "113c50c6-033f-49d0-836b-09aa1988e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = {'len': [], 'source':[]}\n",
    "\n",
    "# Load all the human responses first.\n",
    "len_df['len'] += sample['response'].apply(lambda x: len(x)).values.tolist()\n",
    "len_df['source'] += ['Dolly' for _ in range(len(sample))]\n",
    "\n",
    "for (df, source_name) in [(deep_npnc,'Deepseek-NP'), (deep_p, 'Deepseek-FP')]:\n",
    "    len_df['len'] += df['response'].apply(lambda x: len(x)).values.tolist()\n",
    "    len_df['source'] += [source_name for _ in range(len(df))]\n",
    "    \n",
    "len_df=pd.DataFrame(len_df)\n",
    "\n",
    "g = sns.kdeplot(len_df, x='len', hue='source', common_norm=False, fill=True, clip=[0,8000])\n",
    "g.set_xlabel('Completion length (chars)')\n",
    "g.set_ylabel('Number of responses')\n",
    "g.spines[\"top\"].set_visible(False)\n",
    "g.spines[\"right\"].set_visible(False)\n",
    "g.spines[\"left\"].set_visible(False)\n",
    "g.set(yticklabels=[])\n",
    "g.grid(axis='x')\n",
    "# plt.legend([], [], frameon=False)\n",
    "# plt.show()\n",
    "plt.savefig('length.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64572c-c9b0-4bd5-805b-248947b8d068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
