{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2ac6a1-081d-45f3-a091-56a4aaa8829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ipdb\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from diversity import compression_ratio, ngram_diversity_score, extract_patterns, get_pos, pos_patterns, token_patterns, self_repetition_score\n",
    "import json\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from transformers import AutoTokenizer\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import mplcursors\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid', context='notebook', rc={'figure.figsize':(14,10), 'font.family': 'Times'}, font_scale=3)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('chained_assignment',None)\n",
    "\n",
    "# Set random seeds for reproducibility on a specific machine\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "np.random.RandomState(1)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a24c7ef-0cf7-4d8b-9ac4-09d9ad0dbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cr_nds_sr(responses):\n",
    "    cr = compression_ratio(responses, 'gzip')\n",
    "    nds = ngram_diversity_score(responses, 4)\n",
    "    #CR-POS\n",
    "    joined_pos, tuples = get_pos(responses)\n",
    "    # ngrams_pos = token_patterns(joined_pos, 5, 10)\n",
    "    cr_pos = compression_ratio(joined_pos, 'gzip')\n",
    "    srep = self_repetition_score(responses, verbose=False)\n",
    "    return cr, cr_pos, nds, srep\n",
    "\n",
    "def calc_diversity(df, num_shuffles=10):\n",
    "    '''\n",
    "    Randomly assigns personas with prompts, calculates metrics over responses for these\n",
    "    pairings, then calculates mean and S.D over 10 different random pairings\n",
    "    '''\n",
    "    random.seed(1)\n",
    "    crs = []\n",
    "    ndss = []\n",
    "    crs_pos = []\n",
    "    sreps = []\n",
    "    new_df = df.set_index(['persona_id', 'prompt_id'])\n",
    "    for _ in tqdm(range(num_shuffles)):\n",
    "        # Get random personas paired with every prompt\n",
    "        persona_ids_shuffled = [i for i in range(100)]\n",
    "        random.shuffle(persona_ids_shuffled)\n",
    "        prompt_ids = [i for i in range(100)]\n",
    "        pairs = list(zip(persona_ids_shuffled, prompt_ids))\n",
    "        responses = new_df.loc[pairs, 'response'].values.tolist()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        cr, cr_pos, nds, srep = calc_cr_nds_sr(responses)\n",
    "    \n",
    "        crs.append(cr)\n",
    "        ndss.append(nds)\n",
    "        crs_pos.append(cr_pos)\n",
    "        sreps.append(srep)\n",
    "    \n",
    "    print(f\"CR: {np.round(np.mean(crs),2)} ± {np.round(np.std(crs),2)}\\nCR-POS: {np.round(np.mean(crs_pos),2)} ± {np.round(np.std(crs_pos),2)}\\nNDS: {np.round(np.mean(ndss),2)} ± {np.round(np.std(ndss),2)}\\nSelf-rep:{np.round(np.mean(sreps),2)} ± {np.round(np.std(sreps),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f0b56-9c5f-4f23-a51d-ae53a9d9458e",
   "metadata": {},
   "source": [
    "## Dolly human responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87eebce1-cd67-49bc-96b9-f4d10a5105e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sample_personas.txt', 'r') as f:\n",
    "    personas = [x.strip() for x in f.readlines()]\n",
    "dolly = load_dataset(\"databricks/databricks-dolly-15k\")[\"train\"].filter(lambda row: row['category']=='creative_writing').to_pandas()\n",
    "sample = pd.read_csv('../data/dolly_creative_prompts_sample.tsv', sep='\\t')\n",
    "sample['response'] = sample['index'].apply(lambda x: dolly.loc[x, 'response'])\n",
    "sample['prompt_id'] = [i for i in range(len(sample))]\n",
    "prompts = sample['instruction'].values.tolist()\n",
    "human_responses = sample['response'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c6ee1b-bc92-4414-b67b-f695ebfd383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating self-repetition score: 100%|██████████████████████████████████████████████████████| 100/100 [00:00<00:00, 103307.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.51\n",
      "NDS: 3.03\n",
      "CR-POS: 4.93\n",
      "Self-rep: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cr = compression_ratio(human_responses, 'gzip')\n",
    "nds = ngram_diversity_score(human_responses, 4)\n",
    "joined_pos, tuples = get_pos(human_responses)\n",
    "# ngrams_pos = token_patterns(joined_pos, 5, 10)\n",
    "cr_pos = compression_ratio(joined_pos, 'gzip')\n",
    "# rouge = homogenization_score(human_responses, 'rougel', verbose=False)\n",
    "# bleu = homogenization_score(human_responses, 'bleu', verbose=False)\n",
    "srep = self_repetition_score(human_responses)\n",
    "# print(f\"CR: {np.round(cr,2)}\\nNDS: {np.round(nds,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nHS-RougeL: {np.round(rouge,2)}\\nself-bleu: {np.round(bleu,2)}\\nSelf-rep: {np.round(srep, 2)}\")\n",
    "print(f\"CR: {np.round(cr,2)}\\nNDS: {np.round(nds,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c69f0-e14a-4cd0-a584-75ed53878414",
   "metadata": {},
   "source": [
    "## Llama-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f178277a-9cdc-4987-ad65-ee18cd4176d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.77\n",
      "CR-POS: 5.73\n",
      "NDS: 2.87\n",
      "Self-rep: 1.89\n"
     ]
    }
   ],
   "source": [
    "# No persona, no cutoff\n",
    "np70_df = pd.read_csv('../output/llama-temp1/llama70b-np/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "np70_df['response'] = np70_df.response.apply(lambda x: x.strip())\n",
    "np70_df = np70_df.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(np70_df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8434efba-be0d-4a80-b553-3c310b6f4015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.57\n",
      "CR-POS: 5.16\n",
      "NDS: 3.08\n",
      "Self-rep: 0.52\n"
     ]
    }
   ],
   "source": [
    "# No persona with cutoff\n",
    "npc70_df = pd.read_csv('../output/llama-temp1/llama70b-cutoff-np/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "npc70_df['response'] = npc70_df.response.apply(lambda x: x.strip())\n",
    "npc70_df = npc70_df.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(npc70_df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70942c7-e812-4b7e-8aa5-32c0cd26fbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [10:09<00:00,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.71 ± 0.01\n",
      "CR-POS: 5.38 ± 0.03\n",
      "NDS: 2.84 ± 0.01\n",
      "Self-rep:2.5 ± 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "persona70_df = pd.read_csv('../output/llama-temp1/llama70b-persona/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "persona70_df['response'] = persona70_df.response.apply(lambda x: x.strip())\n",
    "persona70_df = persona70_df.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "calc_diversity(persona70_df, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d9439fd-6c86-4e8d-98fe-1ee21ed7652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:51<00:00,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.51 ± 0.02\n",
      "CR-POS: 5.04 ± 0.03\n",
      "NDS: 3.08 ± 0.02\n",
      "Self-rep:0.68 ± 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Persona plus cutoff\n",
    "personac70_df = pd.read_csv('../output/llama-temp1/llama70b-cutoff-persona/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "personac70_df['response'] = personac70_df.response.apply(lambda x: x.strip())\n",
    "calc_diversity(personac70_df, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8996a9f7-18a5-42ac-baa9-3358b56426ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [10:09<00:00,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.71 ± 0.01\n",
      "CR-POS: 5.41 ± 0.03\n",
      "NDS: 2.85 ± 0.02\n",
      "Self-rep:2.39 ± 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse persona\n",
    "persona70_df_coarse = pd.read_csv('../output/llama-temp1/llama70b-coarse/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "persona70_df_coarse['response'] = persona70_df_coarse.response.apply(lambda x: x.strip())\n",
    "persona70_df_coarse = persona70_df_coarse.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "calc_diversity(persona70_df_coarse, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e0b8eaa-a50e-4348-b139-0f84912ad806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:39<00:00,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.51 ± 0.02\n",
      "CR-POS: 5.06 ± 0.04\n",
      "NDS: 3.09 ± 0.02\n",
      "Self-rep:0.61 ± 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse personas plus cutoff\n",
    "persona70_df_coarse = pd.read_csv('../output/llama-temp1/llama70b-coarse-cutoff/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "persona70_df_coarse['response'] = persona70_df_coarse.response.apply(lambda x: x.strip())\n",
    "persona70_df_coarse = persona70_df_coarse.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "calc_diversity(persona70_df_coarse, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca47f6c-616b-4d7b-9972-0f387d916f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002f398-ec29-407c-bb0d-362c57f54f4b",
   "metadata": {},
   "source": [
    "## Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c10561-66b5-4d44-94ff-b6ab7822c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No persona, no cutoff\n",
    "deep_npnc = pd.read_csv('../output/deepseek/deepseek-np/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_npnc['response'] = deep_npnc.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(deep_npnc['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d8b38-6756-449d-9917-7d46941bc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No persona, cutoff\n",
    "deep_npc = pd.read_csv('../output/deepseek-np-cutoff/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_npc['response'] = deep_npc.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(deep_npc['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648e96e-7c4c-41f3-bfeb-199ae8b5824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persona\n",
    "deep_p = pd.read_csv('../output/deepseek/deepseek-persona/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_p['response'] = deep_p.response.apply(lambda x: x.strip())\n",
    "deep_p = deep_p.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "# calc_diversity(deep_p, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe93f98-e227-4b34-954f-4a78f6a2ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persona cutoff\n",
    "deep_pc = pd.read_csv('../output/deepseek-cutoff-persona/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_pc['response'] = deep_pc.response.apply(lambda x: x.strip())\n",
    "deep_pc = deep_pc.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "# calc_diversity(deep_pc, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b87a6-f7e7-40cb-9b23-c8492890e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarse persona cutoff\n",
    "deep_pc_coarse = pd.read_csv('../output/coarse/deepseek-cutoff-persona/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_pc_coarse['response'] = deep_pc_coarse.response.apply(lambda x: x.strip())\n",
    "deep_pc_coarse = deep_pc_coarse.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(deep_pc_coarse,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f414294-7e24-499a-bccb-1fa96dfd05bd",
   "metadata": {},
   "source": [
    "## Llama-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1369fcea-8317-4bbd-ad48-b29e1e08a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama8b-np/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04e539-7f50-4472-987e-54337acad399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No persona, plus cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama8b-cutoff-np/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd9161-60f8-497a-8175-7ae88694047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama8b-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14395b29-4b8d-422d-b72f-7a6b048c4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine persona, cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama8b-cutoff-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77b62d-b820-4c12-9f0f-546f70ab081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarse persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-coarse/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa4d27-ca35-4f96-b6bc-8910f9addcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarse persona with cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama8b-coarse-cutoff/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df08e3-ad61-4f35-bbe9-c0540cb041dd",
   "metadata": {},
   "source": [
    "## Llama-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ec794-4df6-4b2a-8a25-c1812a8f8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama1b-np/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70eb176-e8e5-474d-b66b-ac3f483d2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No persona, cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama1b-cutoff-np/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbc726-cbd2-42db-b9ad-69fcf13e6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama1b-persona/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adaa14c-450b-457e-b492-54ff58b73819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine persona, cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama1b-cutoff-persona/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f935c-2368-4d12-95a1-402b7b322bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarse persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama1b-coarse/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d46850-9b5d-49ea-9514-2137d385e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarse persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp1/llama1b-coarse-cutoff/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b9dab-18d3-4f30-a2f9-40a61ab15fe7",
   "metadata": {},
   "source": [
    "## Response length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc282d6-6773-4a1d-a10c-50f6cb5979df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-V3-0324')\n",
    "tokenizer('world hello', add_special_tokens=False)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c9d2a-50d4-43af-a61d-080838bccee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = {'len': [], 'source':[]}\n",
    "\n",
    "# Load all the human responses first.\n",
    "len_df['len'] += sample['response'].apply(lambda x: len(tokenizer(x, add_special_tokens=False)['input_ids'])).values.tolist()\n",
    "len_df['source'] += ['Dolly' for _ in range(len(sample))]\n",
    "\n",
    "for (df, source_name) in [(deep_npnc,'Deepseek-NP'), (deep_p, 'Deepseek-FP')]:\n",
    "    if df.shape[0]>100:\n",
    "        df['len'] = df.response.apply(lambda x: len(tokenizer(x, add_special_tokens=False)['input_ids']))\n",
    "        len_df['len'] += df.loc[:, ['prompt_id', 'len']].groupby('prompt_id').mean().len.values.tolist()\n",
    "    else:\n",
    "        len_df['len'] += df['response'].apply(lambda x: len(tokenizer(x, add_special_tokens=False)['input_ids'])).values.tolist()\n",
    "    len_df['source'] += [source_name for _ in range(100)]\n",
    "    \n",
    "len_df=pd.DataFrame(len_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362f327-229d-48f7-bf4a-d7d1e82948ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.kdeplot(len_df, x='len', hue='source', common_norm=False, fill=True, clip=[0,1500])\n",
    "g.set_xlabel('Completion length (tokens)')\n",
    "g.set_ylabel('')\n",
    "g.spines[\"top\"].set_visible(False)\n",
    "g.spines[\"right\"].set_visible(False)\n",
    "g.spines[\"left\"].set_visible(False)\n",
    "g.set(yticklabels=[])\n",
    "g.grid(axis='x')\n",
    "# plt.legend([], [], frameon=False)\n",
    "# plt.show()\n",
    "plt.savefig('length.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c50c6-033f-49d0-836b-09aa1988e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = {'len': [], 'source':[]}\n",
    "\n",
    "# Load all the human responses first.\n",
    "len_df['len'] += sample['response'].apply(lambda x: len(x)).values.tolist()\n",
    "len_df['source'] += ['Dolly' for _ in range(len(sample))]\n",
    "\n",
    "for (df, source_name) in [(deep_npnc,'Deepseek-NP'), (deep_p, 'Deepseek-FP')]:\n",
    "    len_df['len'] += df['response'].apply(lambda x: len(x)).values.tolist()\n",
    "    len_df['source'] += [source_name for _ in range(len(df))]\n",
    "    \n",
    "len_df=pd.DataFrame(len_df)\n",
    "\n",
    "g = sns.kdeplot(len_df, x='len', hue='source', common_norm=False, fill=True, clip=[0,8000])\n",
    "g.set_xlabel('Completion length (chars)')\n",
    "g.set_ylabel('Number of responses')\n",
    "g.spines[\"top\"].set_visible(False)\n",
    "g.spines[\"right\"].set_visible(False)\n",
    "g.spines[\"left\"].set_visible(False)\n",
    "g.set(yticklabels=[])\n",
    "g.grid(axis='x')\n",
    "# plt.legend([], [], frameon=False)\n",
    "# plt.show()\n",
    "plt.savefig('length.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64572c-c9b0-4bd5-805b-248947b8d068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
