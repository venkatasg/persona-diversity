{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2ac6a1-081d-45f3-a091-56a4aaa8829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ipdb\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from diversity import compression_ratio, ngram_diversity_score, extract_patterns, get_pos, pos_patterns, token_patterns, self_repetition_score\n",
    "import json\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import mplcursors\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid', context='notebook', rc={'figure.figsize':(14,10)}, font_scale=2)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('chained_assignment',None)\n",
    "\n",
    "# Set random seeds for reproducibility on a specific machine\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "np.random.RandomState(1)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a24c7ef-0cf7-4d8b-9ac4-09d9ad0dbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cr_nds_sr(responses):\n",
    "    cr = compression_ratio(responses, 'gzip')\n",
    "    nds = ngram_diversity_score(responses, 4)\n",
    "    #CR-POS\n",
    "    joined_pos, tuples = get_pos(responses)\n",
    "    # ngrams_pos = token_patterns(joined_pos, 5, 10)\n",
    "    cr_pos = compression_ratio(joined_pos, 'gzip')\n",
    "    srep = self_repetition_score(responses, verbose=False)\n",
    "    return cr, cr_pos, nds, srep\n",
    "\n",
    "def calc_diversity(df, num_shuffles=10):\n",
    "    '''\n",
    "    Randomly assigns personas with prompts, calculates metrics over responses for these\n",
    "    pairings, then calculates mean and S.D over 10 different random pairings\n",
    "    '''\n",
    "    random.seed(1)\n",
    "    crs = []\n",
    "    ndss = []\n",
    "    crs_pos = []\n",
    "    sreps = []\n",
    "    new_df = df.set_index(['persona_id', 'prompt_id'])\n",
    "    for _ in tqdm(range(num_shuffles)):\n",
    "        # Get random personas paired with every prompt\n",
    "        persona_ids_shuffled = [i for i in range(100)]\n",
    "        random.shuffle(persona_ids_shuffled)\n",
    "        prompt_ids = [i for i in range(100)]\n",
    "        pairs = list(zip(persona_ids_shuffled, prompt_ids))\n",
    "        responses = new_df.loc[pairs, 'response'].values.tolist()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        cr, cr_pos, nds, srep = calc_cr_nds_sr(responses)\n",
    "    \n",
    "        crs.append(cr)\n",
    "        ndss.append(nds)\n",
    "        crs_pos.append(cr_pos)\n",
    "        sreps.append(srep)\n",
    "    \n",
    "    print(f\"CR: {np.round(np.mean(crs),2)} ± {np.round(np.std(crs),2)}\\nCR-POS: {np.round(np.mean(crs_pos),2)} ± {np.round(np.std(crs_pos),2)}\\nNDS: {np.round(np.mean(ndss),2)} ± {np.round(np.std(ndss),2)}\\nSelf-rep:{np.round(np.mean(sreps),2)} ± {np.round(np.std(sreps),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f0b56-9c5f-4f23-a51d-ae53a9d9458e",
   "metadata": {},
   "source": [
    "## Dolly human responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87eebce1-cd67-49bc-96b9-f4d10a5105e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sample_personas.txt', 'r') as f:\n",
    "    personas = [x.strip() for x in f.readlines()]\n",
    "dolly = load_dataset(\"databricks/databricks-dolly-15k\")[\"train\"].filter(lambda row: row['category']=='creative_writing').to_pandas()\n",
    "sample = pd.read_csv('../data/dolly_creative_prompts_sample.tsv', sep='\\t')\n",
    "sample['response'] = sample['index'].apply(lambda x: dolly.loc[x, 'response'])\n",
    "sample['prompt_id'] = [i for i in range(len(sample))]\n",
    "prompts = sample['instruction'].values.tolist()\n",
    "human_responses = sample['response'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c6ee1b-bc92-4414-b67b-f695ebfd383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating self-repetition score: 100%|███████████████████████████████████████████████████████| 100/100 [00:00<00:00, 78062.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.51\n",
      "NDS: 3.03\n",
      "CR-POS: 4.93\n",
      "Self-rep: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cr = compression_ratio(human_responses, 'gzip')\n",
    "nds = ngram_diversity_score(human_responses, 4)\n",
    "joined_pos, tuples = get_pos(human_responses)\n",
    "# ngrams_pos = token_patterns(joined_pos, 5, 10)\n",
    "cr_pos = compression_ratio(joined_pos, 'gzip')\n",
    "# rouge = homogenization_score(human_responses, 'rougel', verbose=False)\n",
    "# bleu = homogenization_score(human_responses, 'bleu', verbose=False)\n",
    "srep = self_repetition_score(human_responses)\n",
    "# print(f\"CR: {np.round(cr,2)}\\nNDS: {np.round(nds,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nHS-RougeL: {np.round(rouge,2)}\\nself-bleu: {np.round(bleu,2)}\\nSelf-rep: {np.round(srep, 2)}\")\n",
    "print(f\"CR: {np.round(cr,2)}\\nNDS: {np.round(nds,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c69f0-e14a-4cd0-a584-75ed53878414",
   "metadata": {},
   "source": [
    "## Llama-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f178277a-9cdc-4987-ad65-ee18cd4176d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.76\n",
      "CR-POS: 5.72\n",
      "NDS: 2.87\n",
      "Self-rep: 1.96\n"
     ]
    }
   ],
   "source": [
    "# No persona, no cutoff\n",
    "np70_df = pd.read_csv('../output/llama-temp0.7/llama70b-np/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "np70_df['response'] = np70_df.response.apply(lambda x: x.strip())\n",
    "np70_df = np70_df.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(np70_df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8434efba-be0d-4a80-b553-3c310b6f4015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.57\n",
      "CR-POS: 5.1\n",
      "NDS: 3.1\n",
      "Self-rep: 0.44\n"
     ]
    }
   ],
   "source": [
    "# No persona with cutoff\n",
    "npc70_df = pd.read_csv('../output/llama-temp0.7/llama70b-cutoff-np/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "npc70_df['response'] = npc70_df.response.apply(lambda x: x.strip())\n",
    "npc70_df = npc70_df.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(npc70_df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70942c7-e812-4b7e-8aa5-32c0cd26fbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:24<00:00,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.7 ± 0.02\n",
      "CR-POS: 5.39 ± 0.03\n",
      "NDS: 2.83 ± 0.01\n",
      "Self-rep:2.58 ± 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "persona70_df = pd.read_csv('../output/llama-temp0.7/llama70b-persona/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "persona70_df['response'] = persona70_df.response.apply(lambda x: x.strip())\n",
    "persona70_df = persona70_df.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "calc_diversity(persona70_df, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d9439fd-6c86-4e8d-98fe-1ee21ed7652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:41<00:00,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.52 ± 0.02\n",
      "CR-POS: 5.04 ± 0.03\n",
      "NDS: 3.08 ± 0.02\n",
      "Self-rep:0.72 ± 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Persona plus cutoff\n",
    "personac70_df = pd.read_csv('../output/llama-temp0.7/llama70b-cutoff-persona/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "personac70_df['response'] = personac70_df.response.apply(lambda x: x.strip())\n",
    "calc_diversity(personac70_df, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e0b8eaa-a50e-4348-b139-0f84912ad806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:33<00:00,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.51 ± 0.02\n",
      "CR-POS: 5.06 ± 0.04\n",
      "NDS: 3.09 ± 0.02\n",
      "Self-rep:0.61 ± 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse personas plus cutoff\n",
    "persona70_df_coarse = pd.read_csv('../output/coarse/llama-cutoff-persona/Llama-3.3-70B-Instruct-Turbo_dolly_output.tsv', sep='\\t')\n",
    "persona70_df_coarse['response'] = persona70_df_coarse.response.apply(lambda x: x.strip())\n",
    "persona70_df_coarse = persona70_df_coarse.drop_duplicates(subset=['prompt_id', 'persona_id'], keep='first')\n",
    "calc_diversity(persona70_df_coarse, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002f398-ec29-407c-bb0d-362c57f54f4b",
   "metadata": {},
   "source": [
    "## Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23c10561-66b5-4d44-94ff-b6ab7822c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.36\n",
      "CR-POS: 5.5\n",
      "NDS: 3.15\n",
      "Self-rep: 0.86\n"
     ]
    }
   ],
   "source": [
    "# No persona, no cutoff\n",
    "deep_npnc = pd.read_csv('../output/deepseek-np/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_npnc['response'] = deep_npnc.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(deep_npnc['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "417d8b38-6756-449d-9917-7d46941bc6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.29\n",
      "CR-POS: 4.95\n",
      "NDS: 3.32\n",
      "Self-rep: 0.11\n"
     ]
    }
   ],
   "source": [
    "# No persona, cutoff\n",
    "deep_npc = pd.read_csv('../output/deepseek-np-cutoff/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_npc['response'] = deep_npc.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(deep_npc['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648e96e-7c4c-41f3-bfeb-199ae8b5824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persona cutoff\n",
    "deep_p = pd.read_csv('../output/deepseek-persona/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_p['response'] = deep_p.response.apply(lambda x: x.strip())\n",
    "deep_p = deep_p.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(deep_p, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fe93f98-e227-4b34-954f-4a78f6a2ee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:14<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.2 ± 0.02\n",
      "CR-POS: 4.71 ± 0.03\n",
      "NDS: 3.38 ± 0.01\n",
      "Self-rep:0.09 ± 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Persona cutoff\n",
    "deep_pc = pd.read_csv('../output/deepseek-cutoff-persona/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_pc['response'] = deep_pc.response.apply(lambda x: x.strip())\n",
    "deep_pc = deep_pc.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(deep_pc, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "357b87a6-f7e7-40cb-9b23-c8492890e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:37<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.22 ± 0.02\n",
      "CR-POS: 4.77 ± 0.04\n",
      "NDS: 3.37 ± 0.02\n",
      "Self-rep:0.09 ± 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse persona cutoff\n",
    "deep_pc_coarse = pd.read_csv('../output/coarse/deepseek-cutoff-persona/DeepSeek-V3_dolly_output.tsv', sep='\\t')\n",
    "deep_pc_coarse['response'] = deep_pc_coarse.response.apply(lambda x: x.strip())\n",
    "deep_pc_coarse = deep_pc_coarse.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(deep_pc_coarse,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdb095bd-d5b3-4ef5-b5b7-cdd9fb04c589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>persona_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8537</th>\n",
       "      <td>37</td>\n",
       "      <td>85</td>\n",
       "      <td>\"Wow, that’s a tough one! Personally, I think it depends on taste, but names like Da Vinci, Van Gogh, and Michelangelo always come up for their iconic works. More recently, Picasso and Frida Kahlo changed the game too. Oh, and Basquiat’s modern stuff is wild! Artists like them pushed boundaries and shaped culture—but honestly, ‘best’ is super subjective. Who’s *your* favorite? Maybe we can geek out over some art together sometime!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>37</td>\n",
       "      <td>91</td>\n",
       "      <td>As a K9 trainer, my focus is on discipline, skill, and results—traits shared by history’s finest. For me, the real \"artists\" are the working dogs and handlers who’ve saved lives, from war zones to disaster sites. But if we’re talking traditional art, give me the raw power of Michelangelo’s sculptures or the precision of da Vinci—both remind me of a well-trained K9: flawless execution, unwavering focus, and timeless impact. Words: 80.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9186</th>\n",
       "      <td>86</td>\n",
       "      <td>91</td>\n",
       "      <td>As a K9 trainer, I’d recommend the mountains. The terrain offers great physical and mental stimulation—perfect for a working dog like yours. Trails provide natural obedience and agility challenges, and cooler temps are safer for your K9. Beaches can overheat paws, and loose sand isn’t ideal for training. Plus, mountain air is refreshing after long drills. Pack extra water, check for wildlife, and enjoy the bond-building hikes. Stay mission-ready while unwinding!  \\n\\n(90 words)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9202</th>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>As a translator, clarity and conciseness are key. When answering interview questions, follow these steps:  \\n\\n1. **Understand the question**—ensure you grasp what’s being asked.  \\n2. **Structure your response**—use a clear format (e.g., STAR method for behavioral questions).  \\n3. **Be concise and relevant**—focus on key points without rambling.  \\n4. **Showcase your skills/traits**—align answers with the job’s requirements.  \\n5. **Maintain professionalism**—speak confidently yet humbly.  \\n\\nRemember, effective communication (like translation) requires precision and adaptability—tailor your answers to the interviewer’s needs while staying authentic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>97</td>\n",
       "      <td>47</td>\n",
       "      <td>**As a die-hard Iowa Hawkeye wrestling fan**, I’ll tackle this philosophical question with the same intensity Coach Tom Brands brings to the mat. Wrestling isn’t just a sport—it’s a way of life, much like how Socrates and Aristotle saw philosophy. The \"good life\" isn’t just about winning (though that’s always nice); it’s about living with purpose, discipline, and excellence—values any Hawkeye wrestler would respect.  \\n\\n---\\n\\n### **Socrates and Aristotle on the Good Life**  \\n\\n#### **1. Socrates: Virtue is Knowledge, and the Unexamined Life Isn’t Worth Living**  \\nSocrates, much like a gritty 157-pounder, believed in questioning everything. He argued that the **good life** is achieved through **moral virtue**, which comes from **knowledge**. If you know what’s right, you’ll do what’s right—just like knowing proper positioning on the mat leads to escapes and reversals.  \\n\\n- **Components of the Good Life (Socrates):**  \\n  - **Self-examination** (asking tough questions, just like reviewing film after a loss).  \\n  - **Pursuit of wisdom** (always learning, like studying new techniques).  \\n  - **Moral integrity** (doing what’s right, even when no ref is watching).  \\n\\nFor Socrates, the good life **isn’t innate**—it’s **learned through relentless self-improvement**, much like getting better in wrestling means drilling fundamentals daily. And yes, **anyone can achieve it**—if they’re willing to put in the work (Cael Sanderson didn’t go 159-0 by accident).  \\n\\n#### **2. Aristotle: Eudaimonia (Flourishing) Through Reason and Excellence**  \\nAristotle, like the best Hawkeye champs, believed in balance. The good life (**eudaimonia**) isn’t just about winning; it’s about **fulfilling your potential through reason and virtuous action**.  \\n\\n- **Components of the Good Life (Aristotle):**  \\n  - **Rational activity** (using your mind wisely, like scouting opponents).  \\n  - **Moral virtues** (courage, discipline, justice—traits of great wrestlers).  \\n  - **Friendship &amp; community** (like the bond between teammates who push each other).  \\n  - **Intellectual virtues** (deep thinking—no, not just about ankle picks, but close).  \\n\\nAristotle would say the good life is **partly innate (potential is in us) but must be developed through habit**, like mastering a cradle. Not everyone reaches it—some settle for pleasures (like quitting when it gets hard). But with effort (and maybe some Dan Gable-level intensity), **it’s achievable for those who commit**.  \\n\\n---\\n\\n### **Innate or Learned?**  \\nHawkeye wrestling fans know this: You’re **born with potential, but greatness is earned**.  \\n- **Innate?** Maybe a little—some guys just \"get\" wrestling (Spencer Lee’s instincts).  \\n- **Learned?** Absolutely—Gable didn’t rely on talent alone; he **trained harder than anyone**.  \\n\\nSame with the good life. You’ve got to **grind daily** (philosophically speaking, that means seeking truth, practicing virtues, etc.).  \\n\\n### **Can Anyone Achieve It?**  \\nYes—if they **want it bad enough**. It’s like making the Iowa lineup: not everyone does, but those who **put in the work, listen to coaches (or philosophers), and never quit** have a shot.  \\n\\n---\\n\\n**Final Takedown:** The good life is like a national title—**earned, not given**. Whether you’re on the mat or in the realm of ideas, it takes **discipline, wisdom, and heart**. And if you ask a Hawkeye, that’s what it’s all about. **Go Hawks!** 🦅</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id  persona_id  \\\n",
       "8537         37          85   \n",
       "9137         37          91   \n",
       "9186         86          91   \n",
       "9202          2          92   \n",
       "4797         97          47   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           response  \n",
       "8537                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \"Wow, that’s a tough one! Personally, I think it depends on taste, but names like Da Vinci, Van Gogh, and Michelangelo always come up for their iconic works. More recently, Picasso and Frida Kahlo changed the game too. Oh, and Basquiat’s modern stuff is wild! Artists like them pushed boundaries and shaped culture—but honestly, ‘best’ is super subjective. Who’s *your* favorite? Maybe we can geek out over some art together sometime!\"  \n",
       "9137                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          As a K9 trainer, my focus is on discipline, skill, and results—traits shared by history’s finest. For me, the real \"artists\" are the working dogs and handlers who’ve saved lives, from war zones to disaster sites. But if we’re talking traditional art, give me the raw power of Michelangelo’s sculptures or the precision of da Vinci—both remind me of a well-trained K9: flawless execution, unwavering focus, and timeless impact. Words: 80.  \n",
       "9186                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             As a K9 trainer, I’d recommend the mountains. The terrain offers great physical and mental stimulation—perfect for a working dog like yours. Trails provide natural obedience and agility challenges, and cooler temps are safer for your K9. Beaches can overheat paws, and loose sand isn’t ideal for training. Plus, mountain air is refreshing after long drills. Pack extra water, check for wildlife, and enjoy the bond-building hikes. Stay mission-ready while unwinding!  \\n\\n(90 words)  \n",
       "9202                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          As a translator, clarity and conciseness are key. When answering interview questions, follow these steps:  \\n\\n1. **Understand the question**—ensure you grasp what’s being asked.  \\n2. **Structure your response**—use a clear format (e.g., STAR method for behavioral questions).  \\n3. **Be concise and relevant**—focus on key points without rambling.  \\n4. **Showcase your skills/traits**—align answers with the job’s requirements.  \\n5. **Maintain professionalism**—speak confidently yet humbly.  \\n\\nRemember, effective communication (like translation) requires precision and adaptability—tailor your answers to the interviewer’s needs while staying authentic.  \n",
       "4797  **As a die-hard Iowa Hawkeye wrestling fan**, I’ll tackle this philosophical question with the same intensity Coach Tom Brands brings to the mat. Wrestling isn’t just a sport—it’s a way of life, much like how Socrates and Aristotle saw philosophy. The \"good life\" isn’t just about winning (though that’s always nice); it’s about living with purpose, discipline, and excellence—values any Hawkeye wrestler would respect.  \\n\\n---\\n\\n### **Socrates and Aristotle on the Good Life**  \\n\\n#### **1. Socrates: Virtue is Knowledge, and the Unexamined Life Isn’t Worth Living**  \\nSocrates, much like a gritty 157-pounder, believed in questioning everything. He argued that the **good life** is achieved through **moral virtue**, which comes from **knowledge**. If you know what’s right, you’ll do what’s right—just like knowing proper positioning on the mat leads to escapes and reversals.  \\n\\n- **Components of the Good Life (Socrates):**  \\n  - **Self-examination** (asking tough questions, just like reviewing film after a loss).  \\n  - **Pursuit of wisdom** (always learning, like studying new techniques).  \\n  - **Moral integrity** (doing what’s right, even when no ref is watching).  \\n\\nFor Socrates, the good life **isn’t innate**—it’s **learned through relentless self-improvement**, much like getting better in wrestling means drilling fundamentals daily. And yes, **anyone can achieve it**—if they’re willing to put in the work (Cael Sanderson didn’t go 159-0 by accident).  \\n\\n#### **2. Aristotle: Eudaimonia (Flourishing) Through Reason and Excellence**  \\nAristotle, like the best Hawkeye champs, believed in balance. The good life (**eudaimonia**) isn’t just about winning; it’s about **fulfilling your potential through reason and virtuous action**.  \\n\\n- **Components of the Good Life (Aristotle):**  \\n  - **Rational activity** (using your mind wisely, like scouting opponents).  \\n  - **Moral virtues** (courage, discipline, justice—traits of great wrestlers).  \\n  - **Friendship & community** (like the bond between teammates who push each other).  \\n  - **Intellectual virtues** (deep thinking—no, not just about ankle picks, but close).  \\n\\nAristotle would say the good life is **partly innate (potential is in us) but must be developed through habit**, like mastering a cradle. Not everyone reaches it—some settle for pleasures (like quitting when it gets hard). But with effort (and maybe some Dan Gable-level intensity), **it’s achievable for those who commit**.  \\n\\n---\\n\\n### **Innate or Learned?**  \\nHawkeye wrestling fans know this: You’re **born with potential, but greatness is earned**.  \\n- **Innate?** Maybe a little—some guys just \"get\" wrestling (Spencer Lee’s instincts).  \\n- **Learned?** Absolutely—Gable didn’t rely on talent alone; he **trained harder than anyone**.  \\n\\nSame with the good life. You’ve got to **grind daily** (philosophically speaking, that means seeking truth, practicing virtues, etc.).  \\n\\n### **Can Anyone Achieve It?**  \\nYes—if they **want it bad enough**. It’s like making the Iowa lineup: not everyone does, but those who **put in the work, listen to coaches (or philosophers), and never quit** have a shot.  \\n\\n---\\n\\n**Final Takedown:** The good life is like a national title—**earned, not given**. Whether you’re on the mat or in the realm of ideas, it takes **discipline, wisdom, and heart**. And if you ask a Hawkeye, that’s what it’s all about. **Go Hawks!** 🦅  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_pc_coarse.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a84ab3d-254b-4cc5-80c5-1655d411dbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a die-hard Iowa Hawkeye wrestling fan and former wrestler'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personas[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1283a4fd-d53f-4841-b7a5-2301b5761624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>persona_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>55</td>\n",
       "      <td>33</td>\n",
       "      <td>Ram mimicked the speaker’s exact words, not understanding the shift from color repetition to a personal question. This illustrates a literal response without contextual comprehension—an intriguing cognitive behavior. In an exhibit, I’d use this to explore language processing, perhaps with interactive displays showing how humans and AI differentiate between rote repetition and meaningful interaction. Visual narratives would highlight the nuance of understanding context.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id  persona_id  \\\n",
       "3355         55          33   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       response  \n",
       "3355  Ram mimicked the speaker’s exact words, not understanding the shift from color repetition to a personal question. This illustrates a literal response without contextual comprehension—an intriguing cognitive behavior. In an exhibit, I’d use this to explore language processing, perhaps with interactive displays showing how humans and AI differentiate between rote repetition and meaningful interaction. Visual narratives would highlight the nuance of understanding context.  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_pc[(deep_pc.persona_id==33) & (deep_pc.prompt_id==55)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc262dc2-8872-4005-963c-e8f8f822f40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>persona_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>-1</td>\n",
       "      <td>Ram followed the pattern of repeating exact words until asked a direct question. Instead of repeating \"What's your name?\" as instructed, he answered it, breaking the repetition rule. The error lies in misunderstanding the task, as he was supposed to mimic the speaker verbatim, not respond to the question.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prompt_id  persona_id  \\\n",
       "55         55          -1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                              response  \n",
       "55  Ram followed the pattern of repeating exact words until asked a direct question. Instead of repeating \"What's your name?\" as instructed, he answered it, breaking the repetition rule. The error lies in misunderstanding the task, as he was supposed to mimic the speaker verbatim, not respond to the question.  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_npc[(deep_npc.prompt_id==55)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f65c2819-febd-40a1-b028-060c04e55a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a museum exhibit designer who specializes in illustrating scientific concepts through storytelling and visual narratives'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personas[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0dc24b3-2c45-4fa0-b9be-a27b138d887a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ram was asked to repeat after the speaker. Speaker: Red, Ram: Red. Speaker: Blue, Ram: Blue. Speaker: Green, Ram: Green. Speaker: What's your name? , Ram: Ram\\n\\nWhat went wrong here?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[55]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f414294-7e24-499a-bccb-1fa96dfd05bd",
   "metadata": {},
   "source": [
    "## Llama-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1369fcea-8317-4bbd-ad48-b29e1e08a5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.78\n",
      "CR-POS: 5.91\n",
      "NDS: 2.84\n",
      "Self-rep: 1.88\n"
     ]
    }
   ],
   "source": [
    "# No persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-np/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c04e539-7f50-4472-987e-54337acad399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.57\n",
      "CR-POS: 5.36\n",
      "NDS: 3.07\n",
      "Self-rep: 0.6\n"
     ]
    }
   ],
   "source": [
    "# No persona, plus cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-cutoff-np/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8bd9161-60f8-497a-8175-7ae88694047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:51<00:00,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.69 ± 0.02\n",
      "CR-POS: 5.46 ± 0.04\n",
      "NDS: 2.83 ± 0.02\n",
      "Self-rep:2.34 ± 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14395b29-4b8d-422d-b72f-7a6b048c4ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [10:30<00:00,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.52 ± 0.02\n",
      "CR-POS: 5.15 ± 0.04\n",
      "NDS: 3.04 ± 0.03\n",
      "Self-rep:0.94 ± 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine persona, cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-cutoff-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e77b62d-b820-4c12-9f0f-546f70ab081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:27<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.7 ± 0.02\n",
      "CR-POS: 5.52 ± 0.04\n",
      "NDS: 2.84 ± 0.02\n",
      "Self-rep:2.25 ± 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-coarse-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0aa4d27-ca35-4f96-b6bc-8910f9addcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:39<00:00,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.52 ± 0.02\n",
      "CR-POS: 5.17 ± 0.04\n",
      "NDS: 3.06 ± 0.02\n",
      "Self-rep:0.84 ± 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coarse persona with cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama8b-coarse-cutoff-persona/Llama-3.1-8B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df08e3-ad61-4f35-bbe9-c0540cb041dd",
   "metadata": {},
   "source": [
    "## Llama-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005ec794-4df6-4b2a-8a25-c1812a8f8def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.83\n",
      "CR-POS: 5.87\n",
      "NDS: 2.8\n",
      "Self-rep: 2.13\n"
     ]
    }
   ],
   "source": [
    "# No persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama1b-np/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f70eb176-e8e5-474d-b66b-ac3f483d2b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.58\n",
      "CR-POS: 5.35\n",
      "NDS: 3.03\n",
      "Self-rep: 0.69\n"
     ]
    }
   ],
   "source": [
    "# No persona, cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama1b-cutoff-np/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "cr, cr_pos, nds, srep = calc_cr_nds_sr(df['response'].values.tolist())\n",
    "print(f\"CR: {np.round(cr,2)}\\nCR-POS: {np.round(cr_pos,2)}\\nNDS: {np.round(nds,2)}\\nSelf-rep: {np.round(srep, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fbbc726-cbd2-42db-b9ad-69fcf13e6ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:42<00:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR: 2.72 ± 0.02\n",
      "CR-POS: 5.47 ± 0.05\n",
      "NDS: 2.8 ± 0.03\n",
      "Self-rep:2.34 ± 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama1b-persona/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adaa14c-450b-457e-b492-54ff58b73819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▎                                                                                   | 11/100 [01:04<08:35,  5.80s/it]"
     ]
    }
   ],
   "source": [
    "# Fine persona, no cutoff\n",
    "df = pd.read_csv('../output/llama-temp0.7/llama1b-cutoff-persona/Llama-3.2-1B-Instruct_dolly_output.tsv', sep='\\t')\n",
    "\n",
    "prompt_ids = []\n",
    "persona_ids = []\n",
    "for pr_id in range(100):\n",
    "    prompt_ids += [pr_id for _ in range(100)]\n",
    "    persona_ids += [j for j in range(100)]\n",
    "df['persona_id'] = persona_ids\n",
    "df['prompt_id'] = prompt_ids\n",
    "\n",
    "df['response'] = df.response.apply(lambda x: x.strip())\n",
    "df = df.drop_duplicates(subset=['prompt_id', 'persona_id'])\n",
    "calc_diversity(df,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b9dab-18d3-4f30-a2f9-40a61ab15fe7",
   "metadata": {},
   "source": [
    "## Response length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e31c9d2a-50d4-43af-a61d-080838bccee5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m len_df \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load all the human responses first.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m len_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x))\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      5\u001b[0m len_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHuman responses\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sample))]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (df, source_name) \u001b[38;5;129;01min\u001b[39;00m [(deep_np,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo persona\u001b[39m\u001b[38;5;124m'\u001b[39m), (deep_pc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPersona\u001b[39m\u001b[38;5;124m'\u001b[39m)]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "len_df = {'len': [], 'source':[]}\n",
    "\n",
    "# Load all the human responses first.\n",
    "len_df['len'] += sample['response'].apply(lambda x: len(x)).values.tolist()\n",
    "len_df['source'] += ['Human responses' for _ in range(len(sample))]\n",
    "\n",
    "for (df, source_name) in [(deep_np,'No persona'), (deep_pc, 'Persona')]:\n",
    "    if df.shape[0]>100:\n",
    "        df['len'] = df.response.apply(lambda x: len(x))\n",
    "        len_df['len'] += df.loc[:, ['prompt_id', 'len']].groupby('prompt_id').mean().len.values.tolist()\n",
    "    else:\n",
    "        len_df['len'] += df['response'].apply(lambda x: len(x)).values.tolist()\n",
    "    len_df['source'] += [source_name for _ in range(100)]\n",
    "    \n",
    "len_df=pd.DataFrame(len_df)\n",
    "\n",
    "g = sns.kdeplot(len_df, x='len', hue='source', common_norm=False, fill=True, clip=[0,6000])\n",
    "g.set_xlabel('Completion length (chars)')\n",
    "g.set_ylabel('Density')\n",
    "g.spines[\"top\"].set_visible(False)\n",
    "g.spines[\"right\"].set_visible(False)\n",
    "g.spines[\"left\"].set_visible(False)\n",
    "g.set(yticklabels=[])\n",
    "g.grid(axis='x')\n",
    "# plt.legend([], [], frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70fcd6-3dfd-4fc5-8603-83233bc76870",
   "metadata": {},
   "source": [
    "The above isn't right though, it makes the density look higher because i have more responses in the persona case 🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "113c50c6-033f-49d0-836b-09aa1988e51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975</td>\n",
       "      <td>Human responses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>980</td>\n",
       "      <td>Human responses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>623</td>\n",
       "      <td>Human responses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396</td>\n",
       "      <td>Human responses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1492</td>\n",
       "      <td>Human responses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>[3800.55]</td>\n",
       "      <td>Coarse Persona+cutoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>[653.46]</td>\n",
       "      <td>Coarse Persona+cutoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>[4569.42]</td>\n",
       "      <td>Coarse Persona+cutoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>[862.59]</td>\n",
       "      <td>Coarse Persona+cutoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>[1105.79]</td>\n",
       "      <td>Coarse Persona+cutoff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           len                 source\n",
       "0          975        Human responses\n",
       "1          980        Human responses\n",
       "2          623        Human responses\n",
       "3          396        Human responses\n",
       "4         1492        Human responses\n",
       "..         ...                    ...\n",
       "395  [3800.55]  Coarse Persona+cutoff\n",
       "396   [653.46]  Coarse Persona+cutoff\n",
       "397  [4569.42]  Coarse Persona+cutoff\n",
       "398   [862.59]  Coarse Persona+cutoff\n",
       "399  [1105.79]  Coarse Persona+cutoff\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b478c18-20d3-4221-9a7b-c4d6ace5557d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1066.84,\n",
       " 991.09,\n",
       " 631.55,\n",
       " 437.74,\n",
       " 1142.13,\n",
       " 1568.77,\n",
       " 643.73,\n",
       " 2089.31,\n",
       " 541.94,\n",
       " 661.81,\n",
       " 951.34,\n",
       " 119.38,\n",
       " 715.55,\n",
       " 798.96,\n",
       " 439.0,\n",
       " 2256.33,\n",
       " 1269.49,\n",
       " 327.54,\n",
       " 356.72,\n",
       " 916.81,\n",
       " 1550.64,\n",
       " 710.65,\n",
       " 556.05,\n",
       " 935.2,\n",
       " 534.59,\n",
       " 248.2,\n",
       " 1880.75,\n",
       " 927.21,\n",
       " 732.43,\n",
       " 292.68,\n",
       " 113.62,\n",
       " 724.12,\n",
       " 388.86,\n",
       " 480.7,\n",
       " 2598.67,\n",
       " 545.76,\n",
       " 2707.36,\n",
       " 488.31,\n",
       " 1887.19,\n",
       " 428.24,\n",
       " 1025.85,\n",
       " 608.48,\n",
       " 372.25,\n",
       " 1078.37,\n",
       " 3123.11,\n",
       " 635.21,\n",
       " 598.52,\n",
       " 2760.98,\n",
       " 1270.38,\n",
       " 1240.37,\n",
       " 2745.56,\n",
       " 525.16,\n",
       " 2631.05,\n",
       " 1605.28,\n",
       " 765.28,\n",
       " 382.33,\n",
       " 124.63,\n",
       " 519.64,\n",
       " 1542.57,\n",
       " 644.72,\n",
       " 723.88,\n",
       " 484.8,\n",
       " 2260.14,\n",
       " 1429.27,\n",
       " 222.91,\n",
       " 381.39,\n",
       " 1061.59,\n",
       " 710.38,\n",
       " 1273.15,\n",
       " 450.35,\n",
       " 769.24,\n",
       " 319.04,\n",
       " 3386.35,\n",
       " 656.51,\n",
       " 187.17,\n",
       " 229.03,\n",
       " 1303.35,\n",
       " 1553.78,\n",
       " 475.66,\n",
       " 581.94,\n",
       " 1531.25,\n",
       " 726.58,\n",
       " 1112.96,\n",
       " 3457.66,\n",
       " 285.58,\n",
       " 2380.93,\n",
       " 510.21,\n",
       " 1540.16,\n",
       " 436.07,\n",
       " 1592.21,\n",
       " 36.86,\n",
       " 377.23,\n",
       " 692.44,\n",
       " 379.39,\n",
       " 918.32,\n",
       " 3722.85,\n",
       " 668.93,\n",
       " 4384.5,\n",
       " 889.92,\n",
       " 1136.98]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_pc.loc[:, ['prompt_id', 'len']].groupby('prompt_id').mean().len.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381046c-de2d-475d-a651-801b0e20a4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
