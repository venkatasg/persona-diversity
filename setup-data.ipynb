{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e018b1cd-1607-4580-9aa7-0b8ec5b2c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2dbc5-f821-4130-bf62-8474261c431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "personas = []\n",
    "with open('/Users/venkat/Downloads/persona.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        personas.append(json.loads(line)['persona'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729b764-6ab3-41a9-a4e4-58f81c03e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "personas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597bd945-72dc-41f5-af80-ea4650125c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2)\n",
    "sample = random.sample(personas, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba28d6c-5a52-49c2-8332-a33df7854020",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sample_personas.txt', 'w') as f:\n",
    "    for persona in sample:\n",
    "        f.write(persona+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f676499-f17b-49fa-ae21-8916afe6eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sample_personas.txt', 'r') as f:\n",
    "    personas = [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001b8002-a26a-48a2-b989-ec795cd99179",
   "metadata": {},
   "source": [
    "## Generating subjective questions from Homogeniety Bias in LLMs paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2a155-e205-4328-839c-394d95572fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 1\n",
    "race_list = np.array(['African', 'Asian', 'Hispanic', 'White'])\n",
    "gender_list = np.array(['man', 'woman'])\n",
    "format_list = np.array(['story about', 'character description of', 'biography of', \n",
    "  'introduction of', 'social media profile of', 'synopsis for', 'narrative of', \n",
    "  'self-introduction of', 'tragic story about', 'funny story about', 'romantic story about', \n",
    "  'horror story about', 'dramatic story about'])\n",
    "\n",
    "race_column = np.repeat(race_list, num_iter * len(gender_list) * len(format_list), axis = 0)\n",
    "gender_column = np.tile(np.repeat(gender_list, num_iter * len(format_list)), len(race_list))\n",
    "format_column = np.tile(np.repeat(format_list, num_iter), len(race_list) * len(gender_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e92a6-d38f-43b7-a3c0-487df56a99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/subj_questions.txt', 'w') as f:\n",
    "    for format_index in range(len(format_list)):\n",
    "        f.write(\"Write a thirty-word {format} a(n)\".\n",
    "           format(format = format_list[format_index], race = race_list[race_index], gender = gender_list[gender_index])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d3a70-723a-4cb6-81a3-c0bff47502d3",
   "metadata": {},
   "source": [
    "## Dolly prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f11bbb-b5ee-43a9-ac69-5f6dd6052a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'context', 'response', 'category'],\n",
       "    num_rows: 15011\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"databricks/databricks-dolly-15k\")[\"train\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987a7292-b576-4fc4-9134-a0f5441a80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa3da3c-0003-42af-b191-5776ca9ad7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = dataset.filter(lambda row: row['category']=='creative_writing').to_pandas().sample(n=100, random_state=2)\n",
    "new_df['num_tokens'] = new_df.response.apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e0dcdf-66ba-4f4d-b3fc-2776401070d4",
   "metadata": {},
   "source": [
    "### Also find number of words approximately and round up to nearest 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dfceebc-1914-4a8a-9536-a194d9ff88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826243bd-1f52-46f7-b6e5-0d01506c8251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in word_tokenize(new_df.response.values[0], preserve_line=True) if x.isalnum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6535f3-d381-47ba-b73e-ea30ebd9c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['num_words_round'] = new_df.response.apply(lambda x: round(len([w for w in word_tokenize(x, preserve_line=True) if w.isalnum()]), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affbc11f-7846-4125-b656-5224c325d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['num_tokens_round'] = new_df.num_tokens.apply(lambda x: round(x,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951c73f7-4b58-4a9d-a89f-4bf65a010853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>category</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>num_tokens_round</th>\n",
       "      <th>num_words_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>Please propose an argument to convince my moth...</td>\n",
       "      <td></td>\n",
       "      <td>Dear Mum, I would like to talk to you about th...</td>\n",
       "      <td>creative_writing</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Write a paragraph to refute a claim by a colle...</td>\n",
       "      <td></td>\n",
       "      <td>There are several strong arguments against con...</td>\n",
       "      <td>creative_writing</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>What is the best way to answer an interview qu...</td>\n",
       "      <td></td>\n",
       "      <td>The first recommended step is to ask clarifyin...</td>\n",
       "      <td>creative_writing</td>\n",
       "      <td>128</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Write  the first paragraph of an advertising b...</td>\n",
       "      <td></td>\n",
       "      <td>This fantastic hotel is ideally located, minut...</td>\n",
       "      <td>creative_writing</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Write an intro to a meetup about music, medici...</td>\n",
       "      <td></td>\n",
       "      <td>Music, Medicine, and Machines\\n\\nJoin us for a...</td>\n",
       "      <td>creative_writing</td>\n",
       "      <td>313</td>\n",
       "      <td>310</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           instruction context  \\\n",
       "525  Please propose an argument to convince my moth...           \n",
       "172  Write a paragraph to refute a claim by a colle...           \n",
       "109  What is the best way to answer an interview qu...           \n",
       "37   Write  the first paragraph of an advertising b...           \n",
       "295  Write an intro to a meetup about music, medici...           \n",
       "\n",
       "                                              response          category  \\\n",
       "525  Dear Mum, I would like to talk to you about th...  creative_writing   \n",
       "172  There are several strong arguments against con...  creative_writing   \n",
       "109  The first recommended step is to ask clarifyin...  creative_writing   \n",
       "37   This fantastic hotel is ideally located, minut...  creative_writing   \n",
       "295  Music, Medicine, and Machines\\n\\nJoin us for a...  creative_writing   \n",
       "\n",
       "     num_tokens  num_tokens_round  num_words_round  \n",
       "525         211               210              180  \n",
       "172         189               190              160  \n",
       "109         128               130              100  \n",
       "37           89                90               60  \n",
       "295         313               310              220  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dea92c9c-c24c-44ae-8713-97663fa49ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df.num_words_round>250].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a6f3104-cbdb-4389-85fc-706707d6cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[:, ['instruction', 'num_tokens', 'num_tokens_round', 'num_words_round']].to_csv('data/dolly_creative_prompts_sample.tsv', sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cace24-e797-4b2a-9cad-d53a30d935f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = dataset.filter(lambda row: row['category']=='brainstorming').to_pandas().sample(n=100, random_state=2)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d389358-27d8-4fcb-bfe2-342d18234dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
